\chapter{Conclusion and Future Work}
\label{chap:conclusion}

Thesis contributions:

- Theory

- Methodology

- Software

Research perspectives:

- machine learning

* theoretical guarantees on rankings
* constitutes an elegant confirmation of the concept of using ranking-related methods for bioinformatics but more ideas to motivate by social choice theory etc
* other cross-subject directions of future research such as pure math (geometric group theory, algebraic group theory, etc) and other biomedical application

- bioinformatics

* far from clinical... In fact, a voluminous literature of $>$150,000 papers documenting thousands of claimed biomarkers has been produced in medicine, of which fewer than 100 have been validated for routine clinical practice \cite{Poste2011Bring}. The very few number of gene expression-based breast cancer prognostic predictors successfully implemented in clinics compared to the number of research findings in this area raises controversies on the practical validity of molecular signatures. issues include: a large number of identified signatures failed to add significantly incremental values to assist prognosis assessment and therapeutic decision making upon the use of conventional clinical covariates; lack of proper validation and clinical utility; cost-effectiveness; etc \cite{Michiels2016Statistical}.
* opportunities come with caveats... overfitting or overly exaggeration of trivial findings... random genes associated to prognosis \cite{Venet2011Most}
* subtyping of breast cancers and prognosis/treatment for each subtype
* integrative data analysis, multi-view multi-omics analysis, incorporating with clinical variables (quote Sage-DREAM BCC)
* meta-analysis with multiple datasets or cross-study validation
* pan-cancer - attractor metagenes
* wet-lab experimental validation
* section 6.3.6 of JP book pitfalls in biomarker discovery

Our knowledge towards cancer biology is still far from complete but we are given the extraordinary opportunity in the era of big data to study cancer.

% ch2-3 embedding for permutations ?!
% other embedding - just (1,\dots,n) or permutation matrix - high-order embedding
% what is the convex hull of Kendall embedding for
%Check Fogel (NIPS, 2013) and Stephen Wright (NIPS, 2014) for two embeddings of symmetric group $\mathbb{S}_n$ into Euclidean spaces, former into dim $n^2$ while latter into dim $n-1$ (or a hyperplane in dim $n$), thus facilitating the convex relaxation to seriation problems by solving an optimization problem constrained in a convex hull, former in Birkhoff polytope
%$$\mathcal{B}:=\{\mathbf{X}\in \mathbb{R}^{n\times n}:\mathbf{X}\succeq 0,\mathbf{X}\mathbf{1}=\mathbf{1},\mathbf{X}^T \mathbf{1}=\mathbf{1}\}$$
%while latter in permutahedron
%$$\mathcal{PH}:=\{x\in \mathbb{R}^n:\sum_{i=1}^n x_i=\frac{n(n+1)}{2},\sum_{i\in S}x_i \leq \sum_{i=1}^{|S|}(n+1-i)\mbox{ for all }S\subset [n]\}.$$
%Kendall kernel comes with another embedding into Euclidean space of dim $O(n^2)$. Several questions are
%\begin{enumerate}
%\item What is the convex hull induced by our embedding? What is the projection of any vector onto the convex hull (to facilitate optimization algorithm using projections)?
%\item On the other way round, what are the explicit embedding, kernel function and distance induced by those two well-known embeddings?
%\item Is it a better embedding compared to those two embeddings to introduce a convex hull for solving seriation problem, when we convert it into an optimization problem by following the same idea as Fogel (NIPS, 2013) after the embedding?
%\end{enumerate}

